<!DOCTYPE html>
<!-- This is an autogenerated file - DO NOT EDIT DIRECTLY -->
<!-- This file was generated on Mon Mar 08 2021 15:50:26 GMT-0800 (Pacific Standard Time) via the forge in willcarh.art v2.0.0-->
<!-- Learn more: https://github.com/wcarhart/willcarh.art -->
<!-- THIS IS A DEVELOPMENT BUILD, PROCEED WITH CAUTION! -->
<html lang="en">
	<head>
		<!-- metadata -->
		<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>willcarh.art</title>
<meta name="description" content="How to Summarize Any Article in 7 Sentences with Software" />
<meta name="twitter:card" value="summary" />
<meta property="og:name" content="willcarh.art" />
<meta property="og:url" content="https://willcarh.art/blog/how-to-summarize-any-article-in-7-sentences-with-software" />
<meta property="og:image" content="../../ico/android-chrome-512x512.png" />
<meta property="og:type" content="website" />
<meta property="og:description" content="How to Summarize Any Article in 7 Sentences with Software" />
<meta property="og:locale" content="en_US" />
<meta property="og:site_name" content="willcarh.art" />

		<!-- CSS -->
		<link rel="stylesheet" href="../../css/common.css">
		<link rel="stylesheet" href="../../css/logo.css">
		<link rel="stylesheet" href="../../css/darkmode.css">
		<link rel="stylesheet" href="../../css/fancylink.css">
		<link rel="stylesheet" href="../../css/linkicons.css">
		<link rel="stylesheet" href="../../css/list.css">
		<link rel="stylesheet" href="../../css/markdown.css">
		<link rel="stylesheet" href="../../css/credits.css">
		<link rel="stylesheet" href="../../css/blog_specific.css">

		<!-- jQuery -->
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

		<!-- Bootstrap CDN -->
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">
		<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx" crossorigin="anonymous"></script>

		<!-- icons -->
		<link rel="apple-touch-icon" sizes="180x180" href="../../ico/apple-touch-icon.png">
	    <link rel="icon" type="image/png" sizes="32x32" href="../../ico/favicon-32x32.png">
	    <link rel="icon" type="image/png" sizes="16x16" href="../../ico/favicon-16x16.png">
	    <link rel="manifest" href="../../ico/site.webmanifest">

	    <!-- FontAwesome -->
	    <script src="https://use.fontawesome.com/releases/v5.5.0/js/all.js"></script>

		<!-- animate.css -->
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css"/>

		<!-- site analytics -->
		<script async defer data-domain="willcarh.art" src="https://plausible.io/js/plausible.js"></script>

		<!-- willcarh.art scripts -->
		<script src="../js/darkmode.js"></script>
		<script src="../js/year.js"></script>
		<script src="../js/epochtime.js"></script>
		<script src="../js/readtime.js"></script>
		<script src="../js/blognav.js"></script>
	</head>
	<body>
		<!-- text content -->
		<div id="content-main">
			<div class="spacer"></div>
			<div id="content-body">
				<div id="word-count" class="hidden-tidbit">1590</div>
<div id="read-time" class="hidden-tidbit">8 min read</div>
<div id="next-blog-link" class="hidden-tidbit">why-im-excited-about-deno</div>
<div id="blog-title-container" class="animate__animated animated_faster animate__fadeInUp animate__delay-1s">
	<h1 id="blog-title">How to Summarize Any Article in 7 Sentences, with Software</h1>
	<h3 id="blog-subtitle">Ain't got time for no readin'</h3>
</div>
<div id="blog-credits" class="animate__animated animated_faster animate__fadeInUp animate__delay-2s">
	<div class="row justify-content-center">
		<div id="blog-author-img-container">
			<img id="blog-author-img" alt="author profile image" src="https://storage.googleapis.com/willcarh-art/img/profile.jpg">
		</div>
		<div id="blog-credits-details">
			<h5 id="blog-author">Will Carhart</h5>
			<p class="blog-metadata epochtime-hover">Published on October 29th, 2020 at 10:23 AM PDT</p>
			<p class="blog-metadata epochtime-hover"></p>
			<p class="blog-metadata readtime-hover"><span class="color">8 min read</span></p>
		</div>
	</div>
</div>
<div id="blog-cover-container" class="animate__animated animated_faster animate__fadeIn animate__delay-4s">
	<img id="blog-cover" alt="How to Summarize Any Article in 7 Sentences, with Software cover image" src="https://storage.googleapis.com/willcarh-art/img/blog/how-to-summarize-any-article-in-7-sentences-with-software/cover.jpg">
</div>

<div id="blog-content-container" class="blog-border animate__animated animated_faster animate__fadeIn animate__delay-4s">
    <h4 class="content-subtitle">Everything comes from Reddit</h4><p class="content-text">Have you ever been on Reddit and seen the <a class="fancy-link" href="https://www.reddit.com/r/autotldr/" target="_blank">autotldr bot</a>? The autotldr bot's purpose is to summarize text articles on Reddit so users don't have to open the article and read it themselves (insert joke about people only reading headlines). This is a really nice feature, as many news sites are littered with popups, paywalls, and trackers, and some don't load well on mobile devices.</p><p class="content-text">Well, I was on Reddit one day and in the thread I was reading the most upvoted comment was the autotldr bot giving a summary about an article. I clicked on the article and found that autotldr's summary was accurate. Not only that, but the article was long and complicated. It had stock tickers and company names, but autotldr summarized in 7 sentences. How could it have done that?</p><br><h4 class="content-subtitle">SMMRY explained</h4><p class="content-text">The autotldr bot is built off of <a class="fancy-link" href="https://smmry.com/" target="_blank">SMMRY</a>, and algorithm that summarizes any text article into 7 sentences. This may seem like black magic, but SMMRY is nice enough to share their pseudocode on their webpage. Here are the steps:</p><ol start=1><li><span>Associate words with their grammatical counterparts. (e.g. "city" and "cities")</span></li><li><span>Calculate the occurrence of each word in the text.</span></li><li><span>Assign each word with points depending on their popularity.</span></li><li><span>Detect which periods represent the end of a sentence. (e.g "Mr." does not).</span></li><li><span>Split up the text into individual sentences.</span></li><li><span>Rank sentences by the sum of their words' points.</span></li><li><span>Return X of the most highly ranked sentences in chronological order.</span></li></ol><h4 class="content-subtitle">Recreating it ourselves</h4><p class="content-text">Given that we can almost take this pseudocode and put a <code class="inline-code">.py</code> extension on it and be done, this seems pretty easy to replicate in Python.</p><p class="content-text">Let's assume we have a single chunk of text in a string. We'll need a smart way to split up the text into sentences. We know that there are only a few characters that can end sentences, like <code class="inline-code">.</code>, <code class="inline-code">?</code>, and <code class="inline-code">!</code>. We'll just need to be careful of abbreviations (e.g. <code class="inline-code">Mrs.</code>, <code class="inline-code">Dr.</code>) and extensions (e.g. <code class="inline-code">.js</code>, <code class="inline-code">.pptx</code>).</p><pre class="code-container"><code class="block-code">import re<br><br>def get_sentences(text):<br>    # attempt to split sentences on .?!<br>    sentences = [chunk for chunk in re.split('([.?!])', text) if not chunk == '' and not chunk.isspace()]<br>    sentences = [x+y for x,y in zip(sentences[0::2], sentences[1::2])]<br><br>    # let's assume that we have a list of known abbreviations in a list called ABB<br>    # and a list of known extensions in a list call EXT<br>    # we'll need to join our sentences together if they were split on an abbreviation or extension<br>    index = 0<br>    while index &lt; len(sentences) - 2:<br>        last_word_previous_sentence = ''.join(character for character in sentences[index].split()[-1].lower() if character.isalnum()).lower()<br>        first_word_next_sentence = ''.join(character for character in sentences[index+1].split()[0].lower() if character.isalnum()).lower()<br>        if (<br>            last_word_previous_sentence in ABB<br>            or first_word_next_sentence in EXT<br>            or len(last_word_previous_sentence) == 1<br>            or len(first_word_next_sentence) == 1<br>        ) and (<br>            not last_word_previous_sentence in ['a', 'i']<br>            and not first_word_next_sentence in ['a', 'i']<br>        ):<br>            sentences[index] = ''.join([sentences[index], sentences[index + 1]])<br>            del sentences[index + 1]<br>        else:<br>            index += 1<br>    return [sentence.strip() for sentence in sentences]</code></pre><p class="content-text">Next, we'll need to determine how often each word occurs, or its frequency. We only want to count <i>meaningful</i> words, so not words like <i>the</i>, <i>a</i>, <i>an</i>, etc. Let's assume we have a list of known words to exclude in a list called <code class="inline-code">EXCLUDE</code>.</p><pre class="code-container"><code class="block-code">def calculate_word_frequency(sentences):<br>    frequencies = {}<br>    words = ' '.join(sentences).split()<br>    raw_words = [''.join(character for character in word if character.isalnum()).lower() for word in words]<br>    for word in raw_words:<br>        if word in EXCLUDE:<br>            frequencies[word] = 0<br>        elif word in frequencies:<br>            frequencies[word] += 1<br>        else:<br>            frequencies[word] = 1<br><br>    if '' in frequencies:<br>        del frequencies['']<br>    return frequencies</code></pre><p class="content-text">Now that we have the frequency of each word, we'll need to score each sentence based on the words it contains. For instance, if we had the frequencies <code class="inline-code">{'the': 0, 'cake': 2, 'is': 0, 'a': 0, 'lie': 5}</code> and the sentence <code class="inline-code">the cake is a lie</code>, then the sentence's score would be <code class="inline-code">7</code>.</p><pre class="code-container"><code class="block-code">def calculate_sentence_scores(sentences, frequencies):<br>    scores = []<br>    for sentence in sentences:<br>        score = 0<br>        for word in sentence.split():<br>            raw_word = ''.join(character for character in word if character.isalnum()).lower()<br>            if raw_word == '':<br>                continue<br>            score += frequencies[raw_word]<br>        scores.append(score)<br><br>    sentence_scores = list(zip(sentences, scores))<br>    return sentence_scores</code></pre><p class="content-text">Great! We're almost done. Now that we have a list of sentences and their scores, we'll just need to return <i>the x highest rated sentences in order</i>. This is where the trick comes in. We don't need any intense NLP or ML because we're using sentences that already exist in the original text and just omitting sentences we've deemed unimportant.</p><pre class="code-container"><code class="block-code">def build_summary(scores, limit):<br>    # build list of sentence indicies<br>    sentence_indices = []<br>    for index, score in enumerate(scores):<br>        sentence_indices.append((index, score[1]))<br><br>    # sort based on sentence score<br>    sorted_sentences = sorted(sentence_indices, key=lambda item: item[1])[::-1]<br><br>    # build list of highest ranked sentences<br>    summary_sentences = []<br>    for index in range(limit):<br>        if index &lt; len(scores) - 1:<br>            summary_sentences.append(scores[sorted_sentences[index][0]][0])<br><br>    summary = ' '.join(summary_sentences)<br>    return summary<br></code></pre><p class="content-text">It's that simple!</p><br><h4 class="content-subtitle">Producing more accurate summaries</h4><p class="content-text">You may have noticed that our code snippets from above do a pretty good job of summarizing text when it's formatted correctly, but what if the it comes from the web? News articles can have code, URLs, and other difficult items to parse. In addition, how do we actually pull the article text out of a news website's webpage?</p><p class="content-text">Let's break down our problems a bit further:</p><ol start=1><li><span>How do we acquire our text from the internet?</span></li><li><span>How do we protect against unwanted words in our sentences (e.g. code, URLs, etc.)?</span></li><li><span>Can we make our summaries more accurate than our current approach?</span></li><li><span>Can we produce metrics on our summarization?</span></li></ol><p class="content-text">How would we solve these issues? Let's take them one at a time:</p><ol start=1><li><span>We can use <a class="fancy-link" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank">BeautifulSoup</a> to scrape the text content of a webpage if we have the URL. We can get the article text be selectively removing HTML components from the webpage.</span></li><li><span>We can add in some checks to remove unwanted components, like checking for code symbols (<code class="inline-code">==</code>, <code class="inline-code">+=</code>, <code class="inline-code">~</code>) and long words (URLs).</span></li><li><span>We could add a heuristic to weight sentences in the beginning of the article heavier. Sentences at the beginning of articles usually provide a more comprehensive summary, while later sentences provide more minor details.</span></li><li><span>We can perform some comparison based on the original text vs. our computed summary.</span></li></ol><h4 class="content-subtitle">Introducing smoosh</h4><p class="content-text">I wanted to see if I could combine our pseudocode from this article with the outline I laid out above into a helpful tool. The result was <a class="fancy-link" href="../project/smoosh.html">smoosh</a>. Smoosh is a command line tool for summarizing text, just like SMMRY and autotldr. It uses a lot of the code snippets from above with some modifications to make the summaries even more accurate. You can find its source code <a class="fancy-link" href="https://github.com/wcarhart/smoosh" target="_blank">here</a>.</p><p class="content-text">If you'd like to take it for a spin, it's easy to install with:</p><pre class="code-container"><code class="block-code">brew install wcarhart/tools/smoosh<br>smoosh --help</code></pre><p class="content-text">And then simple to run with:</p><pre class="code-container"><code class="block-code">smoosh 'https://www.cnn.com/2020/10/27/investing/amd-xilinx-purchase/index.html'</code></pre><br><h4 class="content-subtitle">Conclusion</h4><p class="content-text">I love taking seemingly complex problems and solving them elegantly with software. SMMRY is one of those tools that seems complicated at first glance, but is not actually too difficult to recreate. If you'd like to read more about smoosh, check out its <a class="fancy-link" href="../project/smoosh.html">project page</a> or <a class="fancy-link" href="https://github.com/wcarhart/smoosh" target="_blank">repository</a>. If you'd like to use the code snippets from this post, please access them <a class="fancy-link" href="https://github.com/wcarhart/willcarh.art-snippets/blob/master/how-to-summarize-any-article-in-7-sentences-with-software/snippet.py" target="_blank">here</a>. If you'd like to see smoosh in action, check out <a class="fancy-link" href="../project/lurker.html">lurker</a>, which is another project I wrote that utilizes smoosh to read Hacker News threads on the terminal. You can try SMMRY for yourself <a class="fancy-link" href="https://smmry.com/" target="_blank">here</a>.</p><p class="content-text">Please smoosh responsibly.</p><br><p class="content-text centered-text">ü¶â</p>
</div>
<div class="animate__animated animated_faster animate__fadeIn animate__delay-4s">
	<p id="cover-credit">Artwork by <a class="fancy-link" href="https://stock.adobe.com/contributor/204819955/weris7554" target="_blank">weris7554</a></p>
</div>
<div id="blog-navigation-container" class="animate__animated animated_faster animate__fadeIn animate__delay-4s">
	<div class="row">
		<div class="col-md-1"></div>
		<div id="blog-navigation-back" class="col-md-4 blog-navigation-chunk">
			<h3><span class="show-more">‚üµ</span> Back</h3>
			<p class="navigation-detail-text content-text">Go back to the blog</p>
		</div>
		<div class="col-md-2"></div>
		<div id="blog-navigation-next" class="col-md-4 blog-navigation-chunk">
			<h3>Read More <span class="show-more">‚ü∂</span></h3>
			<p class="navigation-detail-text content-text">Why I'm Excited About Deno</p>
		</div>
		<div class="col-md-1"></div>
	</div>
</div>
<div class="spacer-small"></div>
			</div>
			<div class="spacer"></div>

			<div id="credits" class="row">
	<a id="footer-github-icon" href="https://github.com/wcarhart" target="_blank"><i class="fab fa-github"></i></a>
	<a id="footer-stackoverflow-icon" href="https://stackoverflow.com/users/6246128/wcarhart" target="_blank"><i class="fab fa-stack-overflow" data-fa-transform="left-2"></i></a>
	<a id="footer-linkedin-icon" href="https://linkedin.com/in/willcarhart" target="_blank"><i class="fab fa-linkedin" data-fa-transform="left-2"></i></a>
	<a id="footer-facebook-icon" href="../blog/why-i-deleted-my-facebook.html"><i class="fab fa-facebook-f" data-fa-transform="left-4"></i></a>
	<div style="text-align:center"><a class="fancy-link" href="../etc.html#license">&copy;&nbsp; Will Carhart <span id="year"></span></a></div>
</div>
			<div class="spacer-small"></div>
		</div>

		<!-- logo -->
		<a id="logo-container" href="../../index.html">
	<img id="logo" alt="willcarh.art logo" src="../../ico/android-chrome-512x512.png">
</a>

		<!-- dark mode toggle -->
		<div id="dark-mode-toggle-container">
	<button id="dark-mode-toggle"></button>
</div>
	</body>
</html>